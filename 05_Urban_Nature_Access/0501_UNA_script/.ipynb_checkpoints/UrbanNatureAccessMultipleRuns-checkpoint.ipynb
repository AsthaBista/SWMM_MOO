{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Nature Access Calculation - Monte Carlo Simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model for urban nature access provides a measure of both the supply of urban nature and the demand for nature by the urban population, ultimately calculating the balance between supply and demand.Supply is determined by the type, size, proximity, and quality of urban nature that is accessible per capita for recreational purposes. Demand is determined as natural space per capita, as typically required by policy or standards.\n",
    "\n",
    "InVEST model calculates urban nature access on the basis of each pixel. In this study, the model has been modified to calculate on a subcatchment basis. Here, a method has been proposed to replicate the pixel-based model on a subcatchment level. This was done in order to facilate the Monte Carlo simulations where locations of LIDs in each scenario is not fixed to one pixel, but rather is allocated as a percentage to a subcatchment.\n",
    "\n",
    "In InVEST model, accessible urban nature is calculated as the total area of urban nature accessible to a pixel:\n",
    "$$\n",
    "accessible_i = \\sum_{j=\\{d_{ij} \\leq d_0\\}} S_j \\cdot f(d_{ij})\n",
    "$$\n",
    "\n",
    "People use nature that are at a lesser distance than farther ones. So this model includes a distance decay function f(dij). Here a Gaussian decay function where likelihood to visit far places decreases according to a normal distribution.\n",
    "\n",
    "$$\n",
    "f(d_{ij}, d_0) =\n",
    "\\begin{cases}\n",
    "\\frac{e^{-\\frac{1}{2} \\left( \\frac{d_{ij}}{d_0} \\right)^2} - e^{-\\frac{1}{2}}}{1 - e^{-\\frac{1}{2}}} & \\text{if } d_{ij} \\leq d_0 \\\\\n",
    "0 & \\text{if } d_{ij} > d_0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Simply put, this model applies the following methods:\n",
    "(i) Extract centroids from subcatchment polygons.\n",
    "(ii) Compute a centroid-to-centroid distance matrix.\n",
    "(iii) For each scenario (row in CSV), compute weighted nature area per subcatchment.\n",
    "(iv) For each subcatchment i, compute accessible green space using Gaussian decay from all js with urban nature.\n",
    "(v) Save results in a CSV table, with per-subcatchment and mean UNA scores. \n",
    "\n",
    "Note that the UNA scores obtained are not the absolute value. Since this model does not consider existing nature but only the addition of LIDs, this model determines the marginal gain of UNA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from arcpy import env\n",
    "from arcpy.sa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Settings\n",
    "env.workspace = r\"C:\\Users\\ABI\\OneDrive - NIVA\\Documents\\GitHub\\SWMM_MOO\\GIS_Input_Files\\LorenGIS.gdb\"  \n",
    "arcpy.env.overwriteOutput = True\n",
    "search_radius = 100  # meters\n",
    "lid_csv_path = r\"C:\\Users\\ABI\\OneDrive - NIVA\\Documents\\GitHub\\SWMM_MOO\\01_Preprocessing\\0103_Data_cleaned_random_generated_scenarios.csv\"\n",
    "shapefile_path = r\"C:\\Users\\ABI\\OneDrive - NIVA\\Documents\\GitHub\\SWMM_MOO\\GIS_Input_Files\\Shapefiles\\subcatchments_bdry.shp\"\n",
    "lid_df = pd.read_csv(lid_csv_path, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance between subcatchements is determined from centroid to centroid. Therefore, a centroid matrix is created representing centroids between each subcatchments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid Dict Keys: dict_keys([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n",
      "{1: (265109.48665176687, 6651152.107425284), 2: (265063.2230072711, 6651138.245500137), 3: (265110.6102291129, 6651107.023762066), 4: (265068.5943896611, 6651090.039791075), 5: (265072.29026766913, 6651131.802824572), 6: (265087.25284361135, 6651121.816642927), 7: (265101.35299997835, 6651112.66593823), 8: (265085.9086564888, 6651152.710708944), 9: (265117.946130992, 6651131.682143776), 10: (265060.36631795694, 6651109.66183083), 11: (265091.2825118474, 6651089.592957335)}\n"
     ]
    }
   ],
   "source": [
    "### Creating a distance matrix between each subcatchments and calculating a decay function raster\n",
    "\n",
    "# Creating a dictionary with centroids of all subcatchments\n",
    "subcat_fc = shapefile_path\n",
    "\n",
    "# Get centroid coordinates\n",
    "centroid_dict = {}      # a dictionary to save all coordinates \n",
    "with arcpy.da.SearchCursor(shapefile_path, [\"SID\", \"SHAPE@XY\"]) as cursor:    #SHAPE@XY returns centroids of polygons\n",
    "    for sid, xy in cursor:\n",
    "        sid_num = int(sid.replace(\"S\", \"\"))  # Convert 'S5' â†’ 5\n",
    "        centroid_dict[sid_num] = xy\n",
    "        \n",
    "subcat_ids = list(centroid_dict.keys())\n",
    "print(\"Centroid Dict Keys:\", centroid_dict.keys())\n",
    "print(centroid_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       1      2      3      4      5      6      7      8      9      10     11\n",
      "1    0.00  48.30  45.10  74.33  42.38  37.57  40.27  23.59  22.11  64.92  65.11\n",
      "2   48.30   0.00  56.75  48.50  11.12  29.11  45.92  26.91  55.12  28.73  56.16\n",
      "3   45.10  56.75   0.00  45.32  45.63  27.65  10.84  51.94  25.73  50.31  26.03\n",
      "4   74.33  48.50  45.32   0.00  41.93  36.85  39.81  65.02  64.57  21.28  22.69\n",
      "5   42.38  11.12  45.63  41.93   0.00  17.99  34.80  24.95  45.66  25.15  46.29\n",
      "6   37.57  29.11  27.65  36.85  17.99   0.00  16.81  30.92  32.24  29.51  32.47\n",
      "7   40.27  45.92  10.84  39.81  34.80  16.81   0.00  42.92  25.24  41.10  25.17\n",
      "8   23.59  26.91  51.94  65.02  24.95  30.92  42.92   0.00  38.32  50.06  63.35\n",
      "9   22.11  55.12  25.73  64.57  45.66  32.24  25.24  38.32   0.00  61.65  49.82\n",
      "10  64.92  28.73  50.31  21.28  25.15  29.51  41.10  50.06  61.65   0.00  36.86\n",
      "11  65.11  56.16  26.03  22.69  46.29  32.47  25.17  63.35  49.82  36.86   0.00\n"
     ]
    }
   ],
   "source": [
    "# Now, after getting a dictionary with centroids of all subcatchements, a distance matrix between \n",
    "# the centroids is created.\n",
    "distance_matrix = pd.DataFrame(index=subcat_ids, columns=subcat_ids, dtype=float)\n",
    "\n",
    "for i in subcat_ids:\n",
    "    for j in subcat_ids:\n",
    "        xi, yi = centroid_dict[i]\n",
    "        xj, yj = centroid_dict[j]\n",
    "        d = ((xi - xj) ** 2 + (yi - yj) ** 2) ** 0.5\n",
    "        distance_matrix.loc[i, j] = d\n",
    "        \n",
    "print(distance_matrix.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the csv file with all scenarios\n",
    "lid_df = pd.read_csv(lid_csv_path, delimiter=';')\n",
    "\n",
    "# Initializing\n",
    "nature_weights = {\"BC\": 0.8, \"GS\": 0.7, \"TRE\": 1.0}  # assuming urban nature weights for each LID\n",
    "lid_columns = [\"S5\", \"S7\", \"S8\", \"S9\", \"S10\", \"S11\"]\n",
    "type_columns = [\"S5_Type\", \"S7_Type\", \"S8_Type\", \"S9_Type\", \"S10_Type\", \"S11_Type\"]\n",
    "subcat_lookup = {\"S5\": 5, \"S7\": 7, \"S8\": 8, \"S9\": 9, \"S10\": 10, \"S11\": 11}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function for Gaussian decay function for the operation further\n",
    "def gaussian_decay(d, d0):\n",
    "    if d > d0:\n",
    "        return 0\n",
    "    return (np.exp(-0.5 * (d / d0)**2) - np.exp(-0.5)) / (1 - np.exp(-0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculating urban nature access score for each scenario\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "una_results = []\n",
    "subcat_ids = list(range(1, 12))\n",
    "\n",
    "# Loop around each row for each LID scenario\n",
    "for idx, row in lid_df.iterrows():\n",
    "    \n",
    "    # Loop through the terrain subcatchments S5, S7, S8, S9, S10, S11\n",
    "    green_area = {}    # A dictionary to store all weighted area of urban nature in each subcatchment\n",
    "    for lid_col, type_col in zip(lid_columns, type_columns):\n",
    "        lid_type = row[type_col]\n",
    "        if lid_type in nature_weights:\n",
    "            sid = subcat_lookup[lid_col]                # Extracting integer for using it for distance matrix\n",
    "            weight = nature_weights[lid_type]\n",
    "            green_area[sid] = row[lid_col] * weight     # Multiplies area of new LID with respective weight\n",
    "   # Now applying a Gaussian decay to calculate UNA\n",
    "    access_scores = {}\n",
    "    for i in subcat_ids:\n",
    "        total = 0\n",
    "        for j, S_j in green_area.items():\n",
    "            if j in subcat_ids:\n",
    "                d = distance_matrix.loc[i, j]\n",
    "                if d <= search_radius:\n",
    "                    # Gaussian decay (normalized)\n",
    "                    decay = gaussian_decay(d, search_radius)\n",
    "                    total += S_j * decay\n",
    "        access_scores[i] = total\n",
    "    una_results.append(access_scores)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNA scores saved to: C:\\Users\\ABI\\OneDrive - NIVA\\PhD_Work\\Work\\PartII\\Loren\\InVEST\\UNA\\UNA_results_per_scenario.csv\n",
      "              1           2           3  ...          10          11        Mean\n",
      "Sim                                      ...                                    \n",
      "0      0.000000    0.000000    0.000000  ...    0.000000    0.000000    0.000000\n",
      "1     52.265216   68.250743   59.217452  ...   70.122513   61.822574   63.600461\n",
      "2     65.557532   73.369761   77.193094  ...   76.431902   76.337264   75.415878\n",
      "3    123.080606  127.372266  119.407535  ...  117.744930  108.684348  123.190184\n",
      "4     31.474992   39.111749   31.665507  ...   37.759075   31.780490   35.262134\n",
      "\n",
      "[5 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# === STEP 5: Save output as table ===\n",
    "una_df = pd.DataFrame(una_results)\n",
    "una_df.index.name = \"Sim\"\n",
    "una_df['Mean'] = una_df.mean(axis=1)   # Finding the average UNA in the whole study area\n",
    "\n",
    "output_path = r\"C:\\Users\\ABI\\OneDrive - NIVA\\PhD_Work\\Work\\PartII\\Loren\\InVEST\\UNA\\UNA_results_per_scenario.csv\"\n",
    "una_df.to_csv(output_path, sep=';')\n",
    "\n",
    "print(f\"UNA scores saved to: {output_path}\")\n",
    "print(una_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "una_df['Mean'].hist(bins=30)\n",
    "plt.title('Distribution of Mean UNA Scores Across Scenarios')\n",
    "plt.xlabel('UNA Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
